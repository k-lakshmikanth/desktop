{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow\n",
      "  Downloading Pillow-9.1.1-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 13.1 MB/s eta 0:00:00\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-9.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade azure-cognitiveservices-vision-face\n",
    "#python -m pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition\n",
    "\n",
    "\n",
    "# This key will serve all examples in this document.\n",
    "KEY = \"PASTE_YOUR_FACE_SUBSCRIPTION_KEY_HERE\"\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = \"PASTE_YOUR_FACE_ENDPOINT_HERE\"\n",
    "\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://csdx.blob.core.windows.net/resources/Face/Images/'\n",
    "\n",
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "\n",
      "DETECT FACES\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lakshmikanth\\Desktop\\microsoft_face_api.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lakshmikanth/Desktop/microsoft_face_api.ipynb#ch0000002?line=10'>11</a>\u001b[0m single_image_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(single_face_image_url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lakshmikanth/Desktop/microsoft_face_api.ipynb#ch0000002?line=11'>12</a>\u001b[0m \u001b[39m# We use detection model 3 to get better performance.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lakshmikanth/Desktop/microsoft_face_api.ipynb#ch0000002?line=12'>13</a>\u001b[0m detected_faces \u001b[39m=\u001b[39m face_client\u001b[39m.\u001b[39;49mface\u001b[39m.\u001b[39;49mdetect_with_url(url\u001b[39m=\u001b[39;49msingle_face_image_url, detection_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdetection_03\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lakshmikanth/Desktop/microsoft_face_api.ipynb#ch0000002?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m detected_faces:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lakshmikanth/Desktop/microsoft_face_api.ipynb#ch0000002?line=14'>15</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo face detected from image \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(single_image_name))\n",
      "File \u001b[1;32mc:\\Users\\Lakshmikanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azure\\cognitiveservices\\vision\\face\\operations\\_face_operations.py:543\u001b[0m, in \u001b[0;36mFaceOperations.detect_with_url\u001b[1;34m(self, url, return_face_id, return_face_landmarks, return_face_attributes, recognition_model, return_recognition_model, detection_model, face_id_time_to_live, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/azure/cognitiveservices/vision/face/operations/_face_operations.py?line=539'>540</a>\u001b[0m body_content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_serialize\u001b[39m.\u001b[39mbody(image_url, \u001b[39m'\u001b[39m\u001b[39mImageUrl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/azure/cognitiveservices/vision/face/operations/_face_operations.py?line=541'>542</a>\u001b[0m \u001b[39m# Construct and send request\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/azure/cognitiveservices/vision/face/operations/_face_operations.py?line=542'>543</a>\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mpost(url, query_parameters, header_parameters, body_content)\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/azure/cognitiveservices/vision/face/operations/_face_operations.py?line=543'>544</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39msend(request, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moperation_config)\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/azure/cognitiveservices/vision/face/operations/_face_operations.py?line=545'>546</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Lakshmikanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\msrest\\service_client.py:193\u001b[0m, in \u001b[0;36m_ServiceClientCore.post\u001b[1;34m(self, url, params, headers, content, form_content)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=183'>184</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, content\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, form_content\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=184'>185</a>\u001b[0m     \u001b[39m# type: (str, Optional[Dict[str, str]], Optional[Dict[str, str]], Any, Optional[Dict[str, Any]]) -> ClientRequest\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=185'>186</a>\u001b[0m     \u001b[39m\"\"\"Create a POST request object.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=186'>187</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=187'>188</a>\u001b[0m \u001b[39m    :param str url: The request URL.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=190'>191</a>\u001b[0m \u001b[39m    :param dict form_content: Form content\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=191'>192</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=192'>193</a>\u001b[0m     request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\u001b[39m'\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params, headers, content, form_content)\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=193'>194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m request\n",
      "File \u001b[1;32mc:\\Users\\Lakshmikanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\msrest\\service_client.py:108\u001b[0m, in \u001b[0;36m_ServiceClientCore._request\u001b[1;34m(self, method, url, params, headers, content, form_content)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=98'>99</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request\u001b[39m(\u001b[39mself\u001b[39m, method, url, params, headers, content, form_content):\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=99'>100</a>\u001b[0m     \u001b[39m# type: (str, str, Optional[Dict[str, str]], Optional[Dict[str, str]], Any, Optional[Dict[str, Any]]) -> ClientRequest\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=100'>101</a>\u001b[0m     \u001b[39m\"\"\"Create ClientRequest object.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=101'>102</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=102'>103</a>\u001b[0m \u001b[39m    :param str url: URL for the request.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=105'>106</a>\u001b[0m \u001b[39m    :param dict form_content: Form content\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=106'>107</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=107'>108</a>\u001b[0m     request \u001b[39m=\u001b[39m ClientRequest(method, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_url(url))\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=109'>110</a>\u001b[0m     \u001b[39mif\u001b[39;00m params:\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=110'>111</a>\u001b[0m         request\u001b[39m.\u001b[39mformat_parameters(params)\n",
      "File \u001b[1;32mc:\\Users\\Lakshmikanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\msrest\\service_client.py:155\u001b[0m, in \u001b[0;36m_ServiceClientCore.format_url\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=152'>153</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parsed\u001b[39m.\u001b[39mscheme \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m parsed\u001b[39m.\u001b[39mnetloc:\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=153'>154</a>\u001b[0m     url \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39mlstrip(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=154'>155</a>\u001b[0m     base \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mbase_url\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mrstrip(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=155'>156</a>\u001b[0m     url \u001b[39m=\u001b[39m urljoin(base \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, url)\n\u001b[0;32m    <a href='file:///c%3A/Users/Lakshmikanth/AppData/Local/Programs/Python/Python310/lib/site-packages/msrest/service_client.py?line=156'>157</a>\u001b[0m \u001b[39mreturn\u001b[39;00m url\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Endpoint'"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Detect faces \n",
    "Detect faces in two images (get ID), draw rectangle around a third image.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('DETECT FACES')\n",
    "print()\n",
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://www.biography.com/.image/t_share/MTQ1MzAyNzYzOTgxNTE0NTEz/john-f-kennedy---mini-biography.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03')\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Display the detected face ID in the first single-face image.\n",
    "# Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
    "print('Detected face ID from', single_image_name, ':')\n",
    "for face in detected_faces: print (face.face_id)\n",
    "print()\n",
    "\n",
    "# Save this ID for use in Find Similar\n",
    "first_image_face_ID = detected_faces[0].face_id\n",
    "\n",
    "# Detect the faces in an image that contains multiple faces\n",
    "# Each detected face gets assigned a new ID\n",
    "multi_face_image_url = \"http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg\"\n",
    "multi_image_name = os.path.basename(multi_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces2 = face_client.face.detect_with_url(url=multi_face_image_url, detection_model='detection_03')\n",
    "\n",
    "print('Detected face IDs from', multi_image_name, ':')\n",
    "if not detected_faces2:\n",
    "    raise Exception('No face detected from image {}.'.format(multi_image_name))\n",
    "else:\n",
    "    for face in detected_faces2:\n",
    "        print(face.face_id)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Print image and draw rectangles around faces\n",
    "'''\n",
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://raw.githubusercontent.com/Microsoft/Cognitive-Face-Windows/master/Data/detection1.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03')\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))\n",
    "\n",
    "def drawFaceRectangles() :\n",
    "# Download the image from the url\n",
    "    response = requests.get(single_face_image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "    print('Drawing rectangle around face... see popup for results.')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_faces:\n",
    "        draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "# Display the image in the default image browser.\n",
    "    img.show()\n",
    "\n",
    "# Uncomment this to show the face rectangles.\n",
    "#    drawFaceRectangles()\n",
    "\n",
    "print()\n",
    "'''\n",
    "END - Detect faces\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Create/Train/Detect/Identify Person Group\n",
    "This example creates a Person Group, then trains it. It can then be used to detect and identify faces in other group images.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('PERSON GROUP OPERATIONS')\n",
    "print()\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, \"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, \"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, \"Child\")\n",
    "\n",
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith(\"w\")]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith(\"m\")]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith(\"ch\")]\n",
    "\n",
    "# Add to a woman person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "# Add to a man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "# Add to a child person\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)\n",
    "\n",
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the person group...')\n",
    "# Train the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)\n",
    "\n",
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "test_image_array = glob.glob('test-image-person-group.jpg')\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "print('Pausing for 60 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (60)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_stream(image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}.'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "    if len(person.candidates) > 0:\n",
    "        print('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence)) # Get topmost confidence score\n",
    "    else:\n",
    "        print('No person identified for face ID {} in {}.'.format(person.face_id, os.path.basename(image.name)))\n",
    "print()\n",
    "'''\n",
    "END - Create/Train/Detect/Identify Person Group\n",
    "'''\n",
    "\n",
    "print()\n",
    "print('-----------------------------')\n",
    "print('End of quickstart.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4d92fa7d07125e7ab0aca3f8e20954cbb23630c96258348a18a2a56509bfffe"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
